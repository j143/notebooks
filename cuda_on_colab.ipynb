{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cuda_on_colab.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOdLeSIqFyEskC2fDKUMWsi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Prerequisites"
      ],
      "metadata": {
        "id": "tT4786xJBWKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove existing CUDA installation and NVIDIA drivers"
      ],
      "metadata": {
        "id": "phO2W5bZqdHt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQtstBaofzYT"
      },
      "outputs": [],
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install specific CUDA"
      ],
      "metadata": {
        "id": "6t2vFrA3qlE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "metadata": {
        "id": "Othydrgyf-qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation check"
      ],
      "metadata": {
        "id": "8SnWeOi9qrNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA1C6v_JhI0E",
        "outputId": "7d1c4e18-2b7a-4137-c91b-1d346452ee42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install a jupyter extension"
      ],
      "metadata": {
        "id": "SzaCN9poqvf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LjqG42cgdQQ",
        "outputId": "add369df-174b-48c1-a17f-5545322fc82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-c3a24qus\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-c3a24qus\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=1ab03230e0c2f6d86a45ee1c6aa34a849ca7993f58637842340ac1a223bc2ead\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pljnv_mt/wheels/c5/2b/c0/87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the plugin"
      ],
      "metadata": {
        "id": "tabn9_zlqyx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uVGJjHrhdOu",
        "outputId": "cb63f36b-2823-43f8-ceab-e0923a4f5913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run CUDA"
      ],
      "metadata": {
        "id": "lgumuFZuBsw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run a print example"
      ],
      "metadata": {
        "id": "v0COdZH9q0lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"This is from CUDA\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfhvU2Ghhh_U",
        "outputId": "2caf8db7-e902-46c8-df5d-7826c2fd3c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is from CUDA\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Involved example"
      ],
      "metadata": {
        "id": "rkbs-IDaB14q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void maxi(int* a, int* b, int n)\n",
        "{\n",
        "\tint block = 256 * blockIdx.x;\n",
        "\tint max = 0;\n",
        "\n",
        "\tfor (int i = block; i < min(256 + block, n); i++) {\n",
        "\n",
        "\t\tif (max < a[i]) {\n",
        "\t\t\tmax = a[i];\n",
        "\t\t}\n",
        "\t}\n",
        "\tb[blockIdx.x] = max;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "\tint n;\n",
        "\tn = 3 >> 2;\n",
        "\tint a[n];\n",
        "\n",
        "\tfor (int i = 0; i < n; i++) {\n",
        "\t\ta[i] = rand() % n;\n",
        "\t\tcout << a[i] << \"\\t\";\n",
        "\t}\n",
        "\n",
        "\tcudaEvent_t start, end;\n",
        "\tint *ad, *bd;\n",
        "\tint size = n * sizeof(int);\n",
        "\tcudaMalloc(&ad, size);\n",
        "\tcudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "\tint grids = ceil(n * 1.0f / 256.0f);\n",
        "\tcudaMalloc(&bd, grids * sizeof(int));\n",
        "\n",
        "\tdim3 grid(grids, 1);\n",
        "\tdim3 block(1, 1);\n",
        "\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEventCreate(&end);\n",
        "\tcudaEventRecord(start);\n",
        "\n",
        "\twhile (n > 1) {\n",
        "\t\tmaxi<<<grids, block>>>(ad, bd, n);\n",
        "\t\tn = ceil(n * 1.0f / 256.0f);\n",
        "\t\tcudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "\t}\n",
        "\n",
        "\tcudaEventRecord(end);\n",
        "\tcudaEventSynchronize(end);\n",
        "\n",
        "\tfloat time = 0;\n",
        "\tcudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "\tint ans[2];\n",
        "\tcudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tcout << \"The maximum element is : \" << ans[0] << endl;\n",
        "\n",
        "\tcout << \"The time required : \";\n",
        "\tcout << time << endl;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTOfhmfwh3s4",
        "outputId": "7855693a-2db4-4877-c5b0-9b80b3096581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum element is : 1856785120\n",
            "The time required : 0.004064\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1"
      ],
      "metadata": {
        "id": "7NKE8Zd8kH3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// This is a special function that runs on the GPU (device) instead of the CPU (host)\n",
        "__global__ void kernel() {\n",
        "  printf(\"Hello world!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  // Invoke the kernel function on the GPU with one block of one thread\n",
        "  kernel<<<1,1>>>();\n",
        "\n",
        "  // Check for error codes (remember to do this for _every_ CUDA function)\n",
        "  if(cudaDeviceSynchronize() != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Error: %s\\n\", cudaGetErrorString(cudaPeekAtLastError()));\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoRsWBb-kHWn",
        "outputId": "c728252d-f17e-4cf9-e85f-ee998b886cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2"
      ],
      "metadata": {
        "id": "dZHP7I8yB_Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// This kernel runs on the GPU and prints the thread's identifiers\n",
        "__global__ void kernel() {\n",
        "  printf(\"Hello from block %d thread %d\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  // Launch the kernel on the GPU with four blocks of six threads each\n",
        "  kernel<<<4,6>>>();\n",
        "\n",
        "  // Check for CUDA errors\n",
        "  if(cudaDeviceSynchronize() != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Error: %s\\n\", cudaGetErrorString(cudaPeekAtLastError()));\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKhIVZ2Ckdyb",
        "outputId": "114935ce-8876-4925-9506-0964b81583e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from block 2 thread 0\n",
            "Hello from block 2 thread 1\n",
            "Hello from block 2 thread 2\n",
            "Hello from block 2 thread 3\n",
            "Hello from block 2 thread 4\n",
            "Hello from block 2 thread 5\n",
            "Hello from block 0 thread 0\n",
            "Hello from block 0 thread 1\n",
            "Hello from block 0 thread 2\n",
            "Hello from block 0 thread 3\n",
            "Hello from block 0 thread 4\n",
            "Hello from block 0 thread 5\n",
            "Hello from block 3 thread 0\n",
            "Hello from block 3 thread 1\n",
            "Hello from block 3 thread 2\n",
            "Hello from block 3 thread 3\n",
            "Hello from block 3 thread 4\n",
            "Hello from block 3 thread 5\n",
            "Hello from block 1 thread 0\n",
            "Hello from block 1 thread 1\n",
            "Hello from block 1 thread 2\n",
            "Hello from block 1 thread 3\n",
            "Hello from block 1 thread 4\n",
            "Hello from block 1 thread 5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3"
      ],
      "metadata": {
        "id": "gDACDMfTCDs5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdint.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define N 32\n",
        "#define THREADS_PER_BLOCK 32\n",
        "\n",
        "__global__ void saxpy(float a, float* x, float* y) {\n",
        "  // Which index of the array should this thread use?\n",
        "  size_t index = 20;\n",
        "\n",
        "  // Compute a times x plus y for a specific index\n",
        "  y[index] = a * x[index] + y[index];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  // Allocate arrays for X and Y on the CPU. This memory is only usable on the CPU\n",
        "  float* cpu_x = (float*)malloc(sizeof(float) * N);\n",
        "  float* cpu_y = (float*)malloc(sizeof(float) * N);\n",
        "\n",
        "  // Initialize X and Y\n",
        "  int i;\n",
        "  for(i=0; i<N; i++) {\n",
        "    cpu_x[i] = (float)i;\n",
        "    cpu_y[i] = 0.0;\n",
        "  }\n",
        "\n",
        "  // The gpu_x and gpu_y pointers will only be usable on the GPU (which uses separate memory)\n",
        "  float* gpu_x;\n",
        "  float* gpu_y;\n",
        "\n",
        "  // Allocate space for the x array on the GPU\n",
        "  if(cudaMalloc(&gpu_x, sizeof(float) * N) != cudaSuccess) {\n",
        "    fprintf(stderr, \"Failed to allocate X array on GPU\\n\");\n",
        "    exit(2);\n",
        "  }\n",
        "\n",
        "  // Allocate space for the y array on the GPU\n",
        "  if(cudaMalloc(&gpu_y, sizeof(float) * N) != cudaSuccess) {\n",
        "    fprintf(stderr, \"Failed to allocate Y array on GPU\\n\");\n",
        "    exit(2);\n",
        "  }\n",
        "\n",
        "  // Copy the cpu's x array to the gpu with cudaMemcpy\n",
        "  if(cudaMemcpy(gpu_x, cpu_x, sizeof(float) * N, cudaMemcpyHostToDevice) != cudaSuccess) {\n",
        "    fprintf(stderr, \"Failed to copy X to the GPU\\n\");\n",
        "  }\n",
        "\n",
        "  // Copy the cpu's y array to the gpu with cudaMemcpy\n",
        "  if(cudaMemcpy(gpu_y, cpu_y, sizeof(float) * N, cudaMemcpyHostToDevice) != cudaSuccess) {\n",
        "    fprintf(stderr, \"Failed to copy Y to the GPU\\n\");\n",
        "  }\n",
        "\n",
        "  // Calculate the number of blocks to run, rounding up to include all threads\n",
        "  size_t blocks = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
        "\n",
        "  // Run the saxpy kernel\n",
        "  saxpy<<<blocks, THREADS_PER_BLOCK>>>(0.5, gpu_x, gpu_y);\n",
        "\n",
        "  // Wait for the kernel to finish\n",
        "  if(cudaDeviceSynchronize() != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Error: %s\\n\", cudaGetErrorString(cudaPeekAtLastError()));\n",
        "  }\n",
        "\n",
        "  // Copy the y array back from the gpu to the cpu\n",
        "  if(cudaMemcpy(cpu_y, gpu_y, sizeof(float) * N, cudaMemcpyDeviceToHost) != cudaSuccess) {\n",
        "    fprintf(stderr, \"Failed to copy Y from the GPU\\n\");\n",
        "  }\n",
        "\n",
        "  // Print the updated y array\n",
        "  for(i=0; i<N; i++) {\n",
        "    printf(\"%d: %f\\n\", i, cpu_y[i]);\n",
        "  }\n",
        "\n",
        "  cudaFree(gpu_x);\n",
        "  cudaFree(gpu_y);\n",
        "  free(cpu_x);\n",
        "  free(cpu_y);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKAZmeMekgWp",
        "outputId": "d36ceeb6-47b9-4dac-92be-a9e9a265d17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 0.000000\n",
            "1: 0.000000\n",
            "2: 0.000000\n",
            "3: 0.000000\n",
            "4: 0.000000\n",
            "5: 0.000000\n",
            "6: 0.000000\n",
            "7: 0.000000\n",
            "8: 0.000000\n",
            "9: 0.000000\n",
            "10: 0.000000\n",
            "11: 0.000000\n",
            "12: 0.000000\n",
            "13: 0.000000\n",
            "14: 0.000000\n",
            "15: 0.000000\n",
            "16: 0.000000\n",
            "17: 0.000000\n",
            "18: 0.000000\n",
            "19: 0.000000\n",
            "20: 10.000000\n",
            "21: 0.000000\n",
            "22: 0.000000\n",
            "23: 0.000000\n",
            "24: 0.000000\n",
            "25: 0.000000\n",
            "26: 0.000000\n",
            "27: 0.000000\n",
            "28: 0.000000\n",
            "29: 0.000000\n",
            "30: 0.000000\n",
            "31: 0.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FpLN6GDumQ6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}